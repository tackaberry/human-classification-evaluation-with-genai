{"cells":[{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["PROJECT_ID = \"project-id\" #@param  {allow-input: true}\n","BUCKET = \"bucket-name\" #@param  {allow-input: true}\n","SRC_PATH = \"gdrive/My Drive/folder/images-folder/\" #@param  {allow-input: true}\n","DEST_PATH = \"images/\" #@param  {allow-input: true}\n","BIGQUERY_TABLE = \"dataset.table\" #@param  {allow-input: true}\n","CSV_PATH = 'gdrive/My Drive/folder/data.csv' #@param  {allow-input: true}\n","MODEL= \"gemini-1.5-flash-002\" #@param  {allow-input: true}"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12741,"status":"ok","timestamp":1737342942614,"user":{"displayName":"Brett Tackaberry","userId":"02690462181684780300"},"user_tz":300},"id":"se7uakzXTE9k","outputId":"adae7dea-6187-4bdb-9a78-f8ae198f6b65"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":313},"executionInfo":{"elapsed":901,"status":"ok","timestamp":1737342946464,"user":{"displayName":"Brett Tackaberry","userId":"02690462181684780300"},"user_tz":300},"id":"IBLqmWeoTQzs","outputId":"272d0d3f-ec5b-44f6-c90c-939999281f28"},"outputs":[],"source":["import pandas as pd\n","import json\n","\n","df=pd.read_csv(CSV_PATH)\n","df.head()"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":53,"status":"ok","timestamp":1737342954038,"user":{"displayName":"Brett Tackaberry","userId":"02690462181684780300"},"user_tz":300},"id":"KLB6Yis5WzAt"},"outputs":[],"source":["\n","lookup = {\n","    \"Country\":{\"k\":\"select_label\", \"v\":\"label\"},\n","    \"What language is this label written in?\": {\"k\":\"task_label\", \"v\":\"value\"},\n","    \"County\":{\"k\":\"select_label\", \"v\":\"value\"},\n","    \"DAO Accession Number\\n\": {\"k\":\"task_label\", \"v\":\"value\"},\n","    'Scientific Name': {'k': 'task_label', 'v': 'value'},\n","    'Collected By': {'k': 'task_label', 'v': 'value'},\n","    'Verbatim Date': {'k': 'task_label', 'v': 'value'},\n","    'Are there geographic coordinates present?': {'k': 'task_label', 'v': 'value'},\n","    \"Collection Date (year)\": {'k': 'select_label', 'v': 'label'},\n","    \"Collection Date (month)\": {'k': 'select_label', 'v': 'label'},\n","    'Collection Date (day)': { 'k': 'select_label', 'v': 'label'},\n","}\n","\n","\n","def iterate_json_tree(data, path=\"\"):\n","    if isinstance(data, dict):\n","        for key, value in data.items():\n","            yield from iterate_json_tree(value, path + \"/\" + key if path else key)\n","    elif isinstance(data, list):\n","        for index, value in enumerate(data):\n","            yield from iterate_json_tree(value, path + f\"[{index}]\" if path else f\"[{index}]\")\n","    else:\n","        yield (path, data)\n","\n","\n","def get_data(row):\n","\n","  metadata = json.loads(row[\"metadata\"])\n","\n","  annotations = json.loads(row[\"annotations\"])\n","\n","  subject_data = json.loads(row[\"subject_data\"])\n","\n","  first = next(iter(subject_data))\n","  filename = subject_data[first]['Filename']\n","\n","  obj = {}\n","\n","  for path, value in iterate_json_tree(annotations):\n","    path_parts = path.split(\"/\")\n","    sub_path = \"/\".join(path_parts[:-1])\n","    sub_value = path_parts[-1]\n","\n","    if sub_path not in obj:\n","      obj[sub_path] = {}\n","\n","    obj[sub_path][sub_value] = value\n","\n","  data = {}\n","\n","  for p, o in obj.items():\n","    for label, keys in lookup.items():\n","      if keys[\"k\"] in o and keys[\"v\"] in o and o[keys[\"k\"]]==label:\n","        data[label.replace(\"\\n\",\"\").replace(\"(\",\"\").replace(\")\",\"\")] = o[keys[\"v\"]]\n","\n","  return {\n","      \"classification_id\": row[\"classification_id\"],\n","      \"filename\": filename,\n","      \"data\": data,\n","      \"metadata\": metadata,\n","      \"subject_data\": subject_data,\n","      \"annotations\": annotations,\n","  }\n","\n","\n","def upload_file(bucket_name, filename):\n","    \"\"\"Uploads a file to the bucket, skipping if it already exists.\"\"\"\n","\n","    destination_blob_name = DEST_PATH + filename\n","    source_file_name = SRC_PATH + filename\n","\n","    storage_client = storage.Client()\n","    bucket = storage_client.bucket(bucket_name)\n","    blob = bucket.blob(destination_blob_name)\n","\n","    if blob.exists():\n","        print(f\"File {destination_blob_name} already exists in bucket {bucket_name}. Skipping upload.\")\n","        return\n","\n","    blob.upload_from_filename(source_file_name)\n","\n","    print(f\"File {source_file_name} uploaded to gs://{bucket_name}/{destination_blob_name}.\")\n","\n","\n","def get_ai_generation(image_uri):\n","\n","  model = GenerativeModel(MODEL)\n","\n","  response_schema = {\n","        \"type\": \"object\",\n","        \"properties\": {\n","            \"content\": {\n","                \"type\": \"string\",\n","            },\n","            \"Scientific Name\": {\n","                \"type\": \"string\"\n","            },\n","            \"label language\": {\n","                \"type\": \"string\"\n","            },\n","            \"location\": {\n","                \"type\": \"object\",\n","                \"properties\": {\n","                    \"Location Verbatim\": {\n","                        \"type\": \"string\"\n","                    },\n","                    \"Location Verbatim English\": {\n","                        \"type\": \"string\"\n","                    },\n","                    \"country\": {\n","                        \"type\": \"string\"\n","                    },\n","                    \"county\": {\n","                        \"type\": \"string\"\n","                    },\n","                    \"Are there geographic coordinates present?\": {\n","                        \"type\": \"boolean\"\n","                    },\n","                    \"Lat Long\":{\n","                        \"type\": \"string\"\n","                    }\n","                }\n","            },\n","            \"date\":{\n","                \"type\": \"object\",\n","                \"properties\": {\n","                  \"Verbatim Date\": {\n","                      \"type\": \"string\"\n","                  },\n","                  \"Year\": {\n","                      \"type\": \"integer\"\n","                  }\n","                }\n","            },\n","            \"Identification Numbers\": {\n","                \"type\":\"array\",\n","                \"items\": {\n","                    \"type\": \"string\",\n","                }\n","            },\n","            \"Collected by\":{\n","                \"type\": \"string\"\n","            },\n","\n","        },\n","        \"required\": [\"content\", \"label language\", \"Identification Numbers\", \"location\"],\n","\n","  }\n","\n","  prompt = {\n","      \"Instructions\": \"Help describe what is in this image. \",\n","      \"Important Notes\": [\n","        \"there may be more than one identification numbers\",\n","        \"any country or label language format should be uppercase 2 character ISO country code\"\n","      ],\n","  }\n","\n","  response = model.generate_content(\n","      [\n","          Part.from_uri(\n","              image_uri,\n","              mime_type=\"image/jpeg\",\n","          ),\n","          json.dumps(prompt),\n","      ],\n","      generation_config=GenerationConfig(\n","          response_mime_type=\"application/json\", response_schema=response_schema\n","      ),\n","  )\n","\n","  print(\"AI analysis done. \")\n","\n","  response_json = json.loads(response.text)\n","  return response_json\n","\n","\n","\n","def evaluate_classification(image_uri, ai_generation, subject):\n","  model = GenerativeModel(MODEL)\n","\n","  response_schema = {\n","        \"type\": \"object\",\n","        \"properties\": {\n","            \"evaluation\": {\n","                \"type\": \"string\",\n","            },\n","            \"differences\": {\n","                \"type\": \"array\",\n","                \"items\": {\n","                    \"type\": \"string\",\n","                }\n","            },\n","            \"missing fields\": {\n","                \"type\": \"array\",\n","                \"items\": {\n","                    \"type\": \"string\"\n","                }\n","            },\n","            \"score\": {\n","                \"type\": \"integer\"\n","            }\n","\n","        },\n","        \"required\": [\"evaluation\", \"score\"],\n","\n","  }\n","\n","  prompt = {\n","      \"Instructions\": [\n","          \"Please evaluate the human classification against AI generation\",\n","          \"Provide a summary and enumerate the differences.\",\n","          \"Provide a quality score of the human classification from 0 to 5 based on accuracy and completeness\"\n","          \"Identify missing fields in human classification based on required fields\",\n","      ],\n","      \"Important Notes\": [\n","        \"The label language is provided as the 2-character ISO country code\",\n","      ],\n","      \"AI Generation\": ai_generation,\n","      \"Human Classification\": subject[\"data\"],\n","      \"Required fields\": list(lookup.keys()),\n","  }\n","\n","\n","  response = model.generate_content(\n","      [\n","          # Part.from_uri(\n","          #     image_uri,\n","          #     mime_type=\"image/jpeg\",\n","          # ),\n","          json.dumps(prompt),\n","      ],\n","      generation_config=GenerationConfig(\n","          response_mime_type=\"application/json\", response_schema=response_schema\n","      ),\n","  )\n","\n","  print(\"Evaluation done. \")\n","\n","  response_json = json.loads(response.text)\n","  return response_json\n","\n","def add_to_bigquery(record):\n","  bigquery_client.insert_rows_json(BIGQUERY_TABLE, [record])\n","  print(\"Record added to BigQuery.\")\n","\n","def get_completed_classifications():\n","  query = f\"\"\"\n","    SELECT classification_id\n","    FROM `{BIGQUERY_TABLE}`\n","  \"\"\"\n","  query_job = bigquery_client.query(query)\n","  results = query_job.result()\n","  existing_ids = [row.classification_id for row in query_job]\n","\n","  # Convert the list to a Pandas Series for easier comparison\n","  existing_ids_series = pd.Series(existing_ids)\n","  return existing_ids_series"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":47464,"status":"ok","timestamp":1737343008029,"user":{"displayName":"Brett Tackaberry","userId":"02690462181684780300"},"user_tz":300},"id":"ecJgcaj8zDQy","outputId":"5e2522e4-b01b-43cb-bdc2-50ac93d9249b"},"outputs":[],"source":["from google.colab import auth\n","\n","auth.authenticate_user()\n","\n","! gcloud config set project {PROJECT_ID}\n","! gcloud auth application-default login -q"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":9188,"status":"ok","timestamp":1737343020211,"user":{"displayName":"Brett Tackaberry","userId":"02690462181684780300"},"user_tz":300},"id":"z077saAq3DKD"},"outputs":[],"source":["\n","\n","from google.cloud import storage\n","import vertexai\n","from vertexai.generative_models import GenerativeModel, Part, GenerationConfig\n","vertexai.init(project=PROJECT_ID, location=\"us-central1\")\n","\n","from google.cloud import bigquery\n","bigquery_client = bigquery.Client(project=PROJECT_ID)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":341393,"status":"ok","timestamp":1737344081530,"user":{"displayName":"Brett Tackaberry","userId":"02690462181684780300"},"user_tz":300},"id":"CmSMfzfrIOJ7","outputId":"788d3226-268c-4149-a32b-93af07dad49e"},"outputs":[],"source":["\n","existing_ids_series = get_completed_classifications()\n","filtered_df = df[~df['classification_id'].isin(existing_ids_series)]\n","\n","for i in range(0, 50):\n","  subject = get_data(filtered_df.iloc[i])\n","\n","  filename = subject[\"filename\"]\n","\n","  print(f\"({i}) Analyzing {subject['classification_id']} {filename} \")\n","\n","  upload_file(BUCKET, filename)\n","\n","  image_uri = \"gs://\"+BUCKET+\"/\"+DEST_PATH+filename\n","  json_str = json.dumps(subject[\"data\"])\n","\n","\n","  ai_generation = get_ai_generation(image_uri)\n","  evaluation = evaluate_classification(image_uri, ai_generation, subject)\n","\n","  record = {\n","      \"classification_id\": float(subject[\"classification_id\"]),\n","      \"uri\": image_uri,\n","      \"filename\": filename,\n","      \"scientific_name\": ai_generation[\"Scientific Name\"],\n","      \"parsed_annotations\": json.dumps(subject[\"data\"]),\n","      \"ai_generation\": json.dumps(ai_generation),\n","      \"human_evaluation\": json.dumps(evaluation),\n","  }\n","\n","  add_to_bigquery(record)\n","\n"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyNkJ3vkqdVpc6Rb6UjdDp1N","mount_file_id":"1TTDloAq0viiCNv3Cy7hQhmqc_bnrQRpn","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
